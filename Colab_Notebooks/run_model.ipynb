{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "run_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NsKS5hWIJ5B"
      },
      "source": [
        "# If you want to save the Trasnformers checkpoints to your drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dLj6w3H903a",
        "outputId": "cd580914-4cc1-4372-f31f-fdb7da34a5f9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIl0YUnBnzZi"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7kla3vLnBPF",
        "outputId": "b336e410-bbd4-4289-e269-e816698d2470"
      },
      "source": [
        "! pip install \"transformers==3.3.0\"\n",
        "! pip install gcsfs\n",
        "! pip install pytrec_eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/fc/18e56e5b1093052bacf6750442410423f3d9785d14ce4f54ab2ac6b112a6/transformers-3.3.0-py3-none-any.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 15.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 16.5MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 14.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 6.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 6.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 122kB 6.2MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 174kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 184kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 204kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 215kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 225kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 235kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 245kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 256kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 276kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 286kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 296kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 307kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 317kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 337kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 348kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 358kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 368kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 378kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 389kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 409kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 419kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 430kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 440kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 450kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 460kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 471kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 481kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 491kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 501kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 512kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 522kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 532kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 542kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 552kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 563kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 573kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 583kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 593kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 604kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 614kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 624kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 634kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 645kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 655kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 665kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 675kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 686kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 696kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 706kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 716kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 727kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 737kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 747kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 757kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 768kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 778kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 788kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 798kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 808kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 819kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 829kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 839kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 849kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 860kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 870kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 880kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 890kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 901kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 911kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 921kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 931kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 942kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 952kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 962kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 972kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 983kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 993kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/26/c02ba92ecb8b780bdae4a862d351433c2912fe49469dac7f87a5c85ccca6/tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 14.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (1.19.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 35.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 32.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.0) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.0) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.0) (1.15.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.1rc2 transformers-3.3.0\n",
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/a1/f7e7843b89d7a097969ccb3b4f53d626108a73f31c2979e773ce4431ea2d/gcsfs-2021.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.4)\n",
            "Collecting fsspec==2021.04.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.23.0)\n",
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.7.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (56.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.7.4.3)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (20.3.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Installing collected packages: fsspec, multidict, async-timeout, yarl, aiohttp, gcsfs\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.4.0 gcsfs-2021.4.0 multidict-5.1.0 yarl-1.6.3\n",
            "Collecting pytrec_eval\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/03/e6e84df6a7c1265579ab26bbe30ff7f8c22745aa77e0799bba471c0a3a19/pytrec_eval-0.5.tar.gz\n",
            "Building wheels for collected packages: pytrec-eval\n",
            "  Building wheel for pytrec-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec-eval: filename=pytrec_eval-0.5-cp37-cp37m-linux_x86_64.whl size=266837 sha256=9ea402c4358a5c068945457271a87911a15fde6476ebe442e60b3eac3f8b6536\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/66/40/1779aa0a8eb66e088669befe286f695cdfe420ba91ce662127\n",
            "Successfully built pytrec-eval\n",
            "Installing collected packages: pytrec-eval\n",
            "Successfully installed pytrec-eval-0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzFlwRLsoL8d"
      },
      "source": [
        "**Get the code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rQDw3tRKqNI"
      },
      "source": [
        "import sys\n",
        "sys.path.pop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw9ykM-6n5IM",
        "outputId": "d1760bf4-3586-43c8-fdd4-f12553c87922"
      },
      "source": [
        "import sys\n",
        "%cd /content/\n",
        "!test -d ExactMatchMarking || git clone https://github.com/BOUALILILila/ExactMatchMarking.git\n",
        "if not 'ExactMatchMarking' in sys.path:\n",
        "  sys.path += ['ExactMatchMarking']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "rm: cannot remove 'ExactMatchMarking': No such file or directory\n",
            "Cloning into 'ExactMatchMarking'...\n",
            "remote: Enumerating objects: 510, done.\u001b[K\n",
            "remote: Counting objects: 100% (510/510), done.\u001b[K\n",
            "remote: Compressing objects: 100% (340/340), done.\u001b[K\n",
            "remote: Total 510 (delta 359), reused 318 (delta 167), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (510/510), 123.02 KiB | 2.37 MiB/s, done.\n",
            "Resolving deltas: 100% (359/359), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mybi55fAoT7r"
      },
      "source": [
        "**Google Cloud Storage set up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RCbDvDYx13ZB",
        "outputId": "42758048-c783-4b62-c4db-31c1664952fe"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdUFaYR4wwZv"
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJvKZN02w2j4"
      },
      "source": [
        "import os\n",
        "os.environ['COLAB_SKIP_TPU_AUTH'] = '1'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FaSBpUMw6dZ",
        "outputId": "63b921d2-e466-4ae9-bbfc-f0f1286653e3"
      },
      "source": [
        "project_ID=\"YOUR GCS PROJECT ID #@param {type:\"string\"}\n",
        "bucket_name=\"BUCKET NAME\" #@param {type:\"string\"}\n",
        "!gcloud config set project {project_ID} "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhaX0-VoFwaP"
      },
      "source": [
        "# Zero-shot trasnfer setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ4osMoMo20I"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLEoGaMYyoM_",
        "outputId": "98d2043b-ee0d-4b14-f2ba-8b0d60b362bf"
      },
      "source": [
        "## Tain params\n",
        "MODEL_NAME_OR_PATH = \"google/electra-base-discriminator\" #@param {type:\"string\"}\n",
        "# MODEL_TYPE = \"electra\" #@param {type:\"string\"}\n",
        "CHECKPOINT_DIR='/path/to/ckpts' #@param {type:\"string\"}\n",
        "\n",
        "OUTPUT_DIR = \"/path/to/save/predictions\" #@param {type:\"string\"}\n",
        "assert OUTPUT_DIR, 'Must specify an existing GCS bucket name'\n",
        "tf.io.gfile.makedirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# Now we need to specify the input data dir. Should contain the .tfrecord files \n",
        "# and the supporting query-docids mapping files.\n",
        "\n",
        "\n",
        "COLLECTION='robust04 ' #@param {type:\"string\"}\n",
        "\n",
        "STRATEGY= \"sim_pair\" #@param {type:\"string\"}\n",
        "\n",
        "## Train\n",
        "TRAIN_DATA_DIR = \"\" #@param {type:\"string\"}\n",
        "#  Convention:  {TRAIN_DATA_DIR}/ dataset_train_{TRAIN_SET_NAME}.tf\n",
        "TRAIN_SET_NAME= \"\" #@param {type:\"string\"}\n",
        "\n",
        "## Eval\n",
        "EVAL_DATA_DIR = \"gs://path/to/folder/containing/test/datasets/tfrecord/GCS\" #@param {type:\"string\"}\n",
        "\n",
        "# Convention: {EVAL_DATA_DIR}/dataset_dev_{EVAL_SET_NAME}.tf\n",
        "EVAL_SET_NAME= \"\" #@param {type:\"string\"}\n",
        "EVAL_QRELS_FILE_NAME = \"\"#@param {type:\"string\"}\n",
        "\n",
        "# Convention: {EVAL_DATA_DIR}/dataset_test_{TEST_SET_NAME}.tf\n",
        "TEST_SET_NAME = \"robust04_description_doc_body_1000_p150_o75_sim_pair_doc_level_marking\"#@param {type:\"string\"}\n",
        "TEST_QRELS_FILE_NAME = \"\"#@param {type:\"string\"}\n",
        "# output file name :\n",
        "#   predict: predictions_{TEST_SET_NAME}_{OUT_SUFFIX}-{step}\n",
        "#   eval: predictions_{OUT_SUFFIX}_{step}\n",
        "OUT_SUFFIX = \"msmarco-ft\"#@param {type:\"string\"}\n",
        "\n",
        "# Must be on GCS\n",
        "LOG_DIR = \"gs://path/to/log/dir/on/GCS\"#@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://lila_data/output_dir/zero-shot/robust04/electra *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EB_cwCer6s7"
      },
      "source": [
        "## Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjQVRoSA8zVZ",
        "outputId": "85a3cc20-3672-44c4-8e10-0cbcc5879e3d"
      },
      "source": [
        "# coding=utf-8\n",
        "from absl import logging as logger\n",
        "import os, glob, re\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import (\n",
        "    TF2_WEIGHTS_NAME,\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    HfArgumentParser,\n",
        "    PreTrainedTokenizer,\n",
        "    TFAutoModelForSequenceClassification,\n",
        "    TFTrainingArguments,\n",
        ")\n",
        "\n",
        "from Modeling import (\n",
        "    CustomTFTrainer,\n",
        "    CustomTFTrainingArguments,\n",
        "    get_eval_metric,\n",
        "    wrap_relevance_head,\n",
        "    TFElectraForRelevanceClassification,\n",
        ")\n",
        "from args import (\n",
        "    ModelArguments,\n",
        "    DataTrainingArguments,\n",
        ")\n",
        "\n",
        "\n",
        "logger.set_verbosity(logger.INFO)\n",
        "\n",
        "\n",
        "training_args = CustomTFTrainingArguments(\n",
        "    output_dir = OUTPUT_DIR,\n",
        "    do_train = False,\n",
        "    do_eval = False,\n",
        "    do_predict = True,\n",
        "    do_early_stopping = False,\n",
        "    evaluate_during_training = False,\n",
        "    per_device_train_batch_size = 16,\n",
        "    per_device_eval_batch_size = 4,\n",
        "    learning_rate= 3e-6,\n",
        "    weight_decay = 0.01,\n",
        "    adam_epsilon = 1e-8,\n",
        "    num_train_epochs = -1,\n",
        "    max_steps = 100000,\n",
        "    warmup_steps = 10000,\n",
        "    logging_steps = 1000,\n",
        "    save_steps = 5000,\n",
        "    tpu_name = f\"grpc://{os.environ['COLAB_TPU_ADDR']}\",\n",
        "    ckpt_dir = f'{CHECKPOINT_DIR}/{STRATEGY}', # path to the ckpt \n",
        "    eval_all_checkpoints = False,\n",
        "    logging_dir = LOG_DIR,\n",
        ")\n",
        "\n",
        "\n",
        "data_args = DataTrainingArguments(\n",
        "    collection = COLLECTION,\n",
        "    how = 'words',\n",
        "    train_data_dir = TRAIN_DATA_DIR if TRAIN_DATA_DIR else None,\n",
        "    eval_data_dir = EVAL_DATA_DIR if EVAL_DATA_DIR else None,\n",
        "    train_set_name = TRAIN_SET_NAME if TRAIN_SET_NAME else None,\n",
        "    eval_set_name = EVAL_SET_NAME if EVAL_SET_NAME else None,\n",
        "    test_set_name = TEST_SET_NAME if TEST_SET_NAME else None,\n",
        "    out_suffix = OUT_SUFFIX,\n",
        "    eval_qrels_file = EVAL_QRELS_FILE_NAME if EVAL_QRELS_FILE_NAME else None, \n",
        "    test_qrels_file = TEST_QRELS_FILE_NAME if TEST_QRELS_FILE_NAME else None,\n",
        "    max_seq_length = 256,\n",
        ")\n",
        "model_args = ModelArguments(\n",
        "    model_name_or_path = MODEL_NAME_OR_PATH,\n",
        ")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # See all possible arguments in src/transformers/training_args.py\n",
        "    # or by passing the --help flag to this script.\n",
        "    # We now keep distinct sets of args, for a cleaner separation of concerns.\n",
        "\n",
        "    # parser = HfArgumentParser((ModelArguments, DataTrainingArguments, CustomTFTrainingArguments))\n",
        "    # model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
        "\n",
        "    if (\n",
        "        tf.io.gfile.exists(training_args.output_dir)\n",
        "        and tf.io.gfile.listdir(training_args.output_dir)\n",
        "        and training_args.do_train\n",
        "        and not training_args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n",
        "        )\n",
        "\n",
        "    logger.info(\n",
        "        \"n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        training_args.n_gpu,\n",
        "        bool(training_args.n_gpu > 1),\n",
        "        training_args.fp16,\n",
        "    )\n",
        "    logger.info(\"Training/evaluation/prediction parameters %s\", training_args)\n",
        "\n",
        "    if training_args.do_train or training_args.do_eval:\n",
        "       \n",
        "        num_labels = 2\n",
        "        output_mode = 'classification'\n",
        "\n",
        "        # Load pretrained model and tokenizer\n",
        "        #\n",
        "        # Distributed training:\n",
        "        # The .from_pretrained methods guarantee that only one local process can concurrently\n",
        "        # download model & vocab.\n",
        "\n",
        "        config = AutoConfig.from_pretrained(\n",
        "            model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
        "            num_labels=num_labels,\n",
        "            cache_dir=model_args.cache_dir,\n",
        "            output_hidden_states=False,\n",
        "        )\n",
        "\n",
        "        with training_args.strategy.scope():\n",
        "            # We use one single layer classifier on top of ELECTRA as in the BERT model we follow: \n",
        "            # https://github.com/capreolus-ir/capreolus/blob/master/capreolus/reranker/TFBERTMaxP.py\n",
        "            # and define a new model TFElectraForRelevanceClassification \n",
        "            # if MODEL_TYPE.lower()=='electra':\n",
        "            #   model = TFElectraForRelevanceClassification.from_pretrained(\n",
        "            #       model_args.model_name_or_path,\n",
        "            #       from_pt=True if glob.glob(f\"{model_args.model_name_or_path}/*.bin\") else False,\n",
        "            #       config=config,\n",
        "            #       cache_dir=model_args.cache_dir,\n",
        "            #   )\n",
        "            # else:\n",
        "            #   model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "            #       model_args.model_name_or_path,\n",
        "            #       from_pt=True if glob.glob(f\"{model_args.model_name_or_path}/*.bin\") else False,\n",
        "            #       config=config,\n",
        "            #       cache_dir=model_args.cache_dir,\n",
        "            #   )\n",
        "\n",
        "            model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "                  model_args.model_name_or_path,\n",
        "                  from_pt=True if glob.glob(f\"{model_args.model_name_or_path}/*.bin\") else False,\n",
        "                  config=config,\n",
        "                  cache_dir=model_args.cache_dir,\n",
        "              )\n",
        "            model = wrap_relevance_head(model)\n",
        "            \n",
        "\n",
        "\n",
        "        # Get datasets\n",
        "        if training_args.do_train:\n",
        "            filename = os.path.join(data_args.train_data_dir, f'dataset_train_{data_args.train_set_name}.tf')\n",
        "            if tf.io.gfile.exists(filename):\n",
        "                train_dataset, num_train_examples = data_args.doc_processor.get_train_dataset(filename, \n",
        "                                                                            training_args.train_batch_size, training_args.seed)\n",
        "            else:\n",
        "                raise IOError('File does not exist: ', filename)\n",
        "        else:\n",
        "            train_dataset, num_train_examples = None, 0\n",
        "\n",
        "        if training_args.do_eval or training_args.do_early_stopping:\n",
        "            filename = os.path.join(data_args.eval_data_dir, f'dataset_dev_{data_args.eval_set_name}.tf')\n",
        "            ids_file = os.path.join(data_args.eval_data_dir, f'query_pass_ids_dev_{data_args.eval_set_name}.tsv')\n",
        "            if tf.io.gfile.exists(filename):\n",
        "                eval_dataset, num_eval_examples = data_args.doc_processor.get_eval_dataset(filename, \n",
        "                                                                        training_args.eval_batch_size)\n",
        "            else:\n",
        "                raise IOError('File does not exist: ', filename)\n",
        "            if tf.io.gfile.exists(ids_file):\n",
        "                query_doc_ids = pd.read_csv(ids_file, \n",
        "                                            header=None, index_col=None, delimiter='\\t', \n",
        "                                            names=['id','qid','did','pass'], \n",
        "                                            dtype={'id':str, 'qid':str,'did':str})\n",
        "            else:\n",
        "                raise IOError('File does not exist: ', ids_file)\n",
        "\n",
        "            if data_args.eval_qrels_file is not None:\n",
        "                qrels_file = os.path.join(data_args.eval_data_dir, f'{data_args.eval_qrels_file}.tsv')\n",
        "                if tf.io.gfile.exists(qrels_file):\n",
        "                    eval_qrels = pd.read_csv(qrels_file,\n",
        "                                header=None, index_col=None, delimiter='\\t', names=['qid','did','label'], \n",
        "                                dtype={'qid':str,'did':str, 'label':int})\n",
        "                else:\n",
        "                    raise IOError('File does not exist: ', qrels_file)\n",
        "            else:\n",
        "                eval_qrels = None\n",
        "        else:\n",
        "            eval_dataset, num_eval_examples, query_doc_ids, eval_qrels = None, 0, None, None\n",
        "\n",
        "        eval_metric = get_eval_metric(data_args.collection)\n",
        "\n",
        "\n",
        "        # Initialize our Trainer\n",
        "        trainer = CustomTFTrainer(\n",
        "            model = model,\n",
        "            args = training_args,\n",
        "            train_dataset = train_dataset,\n",
        "            num_train_examples = num_train_examples,\n",
        "            eval_dataset = eval_dataset,\n",
        "            num_eval_examples = num_eval_examples,\n",
        "            out_suffix = f'{data_args.eval_set_name}_{data_args.out_suffix}', # eval output file name\n",
        "            eval_metric = eval_metric,\n",
        "            compute_metrics = eval_metric.compute_on_df,\n",
        "            query_doc_ids = query_doc_ids,\n",
        "            eval_qrels = eval_qrels,\n",
        "        )\n",
        "\n",
        "        # Training\n",
        "        if training_args.do_train:\n",
        "            trainer.train()\n",
        "\n",
        "            if not training_args.do_early_stopping:\n",
        "                trainer.save_model()\n",
        "\n",
        "        # Evaluation        \n",
        "        if training_args.do_eval:\n",
        "            logger.info(\"*** Evaluate ***\")\n",
        "\n",
        "            result = trainer.evaluate()\n",
        "            output_eval_file = os.path.join(training_args.output_dir, f\"eval_results_{data_args.eval_set_name}.txt\")\n",
        "\n",
        "            with open(output_eval_file, \"w\") as writer:\n",
        "                logger.info(\"***** Eval results *****\")\n",
        "\n",
        "                for key, value in result.items():\n",
        "                    logger.info(\"  %s = %s\", key, value)\n",
        "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
        "\n",
        "                results.update(result)\n",
        "            # trainer.predict(eval_dataset, num_eval_examples, query_doc_ids, eval_qrels, \n",
        "            #                 f'{data_args.eval_set_name}_{data_args.out_suffix}-final')\n",
        "\n",
        "    # Test\n",
        "    if training_args.do_predict:\n",
        "\n",
        "        checkpoints = list(\n",
        "                os.path.dirname(c)\n",
        "                for c in sorted(\n",
        "                    glob.glob(f'{training_args.ckpt_dir}' + \"/**/\" + TF2_WEIGHTS_NAME, recursive=True),\n",
        "                    key=lambda f: int(\"\".join(filter(str.isdigit, f)) or -1),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        if len(checkpoints) == 0:\n",
        "            raise IOError('No checkpoint found at this location: ', training_args.ckpt_dir)\n",
        "\n",
        "        elif not training_args.eval_all_checkpoints:\n",
        "            if training_args.ckpt_dir in checkpoints:\n",
        "                checkpoints = [training_args.ckpt_dir]\n",
        "            else:\n",
        "                checkpoints = [checkpoints[-1]]    \n",
        "                    \n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "\n",
        "        filename = os.path.join(data_args.eval_data_dir, f'dataset_test_{data_args.test_set_name}.tf')\n",
        "        if tf.io.gfile.exists(filename):\n",
        "            test_dataset, num_test_examples = data_args.doc_processor.get_eval_dataset(filename, \n",
        "                                                    training_args.eval_batch_size)\n",
        "        else: \n",
        "            raise IOError('File does not exist: ', filename)\n",
        "\n",
        "        ids_file = os.path.join(data_args.eval_data_dir, f'query_pass_ids_test_{data_args.test_set_name}.tsv')\n",
        "        if tf.io.gfile.exists(ids_file):\n",
        "            query_doc_ids = pd.read_csv(ids_file,\n",
        "                                header=None, index_col=None, delimiter='\\t', \n",
        "                                names=['id','qid','did','pass'],\n",
        "                                dtype={'id':str, 'qid':str,'did':str})\n",
        "        else: \n",
        "            raise IOError('File does not exist: ', ids_file)\n",
        "\n",
        "        if data_args.test_qrels_file:\n",
        "            qrels_file = os.path.join(data_args.eval_data_dir, f'{data_args.test_qrels_file}.tsv')\n",
        "            if tf.io.gfile.exists(qrels_file):\n",
        "                test_qrels = pd.read_csv(qrels_file, \n",
        "                            header=None, index_col=None, delimiter='\\t', \n",
        "                            names=['qid','did','label'], \n",
        "                            dtype={'qid':str,'did':str, 'label':int})\n",
        "                \n",
        "            else :\n",
        "                raise IOError('File does not exist: ', qrels_file)\n",
        "        else:\n",
        "            test_qrels = None\n",
        "\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if re.match(\".*checkpoint*-[0-9]\", checkpoint) else \"final\"\n",
        "            logger.info(\"Evaluate the following checkpoint-step: %s - %s\", checkpoint, global_step)\n",
        "            print(\"Evaluate the following checkpoint-step:\", checkpoint, global_step)\n",
        "\n",
        "            with training_args.strategy.scope():\n",
        "                # if MODEL_TYPE.lower()=='electra':\n",
        "                #   trained_model = TFElectraForRelevanceClassification.from_pretrained(checkpoint)\n",
        "                # else:\n",
        "                #   trained_model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "                trained_model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "                trained_model = wrap_relevance_head(trained_model)\n",
        "\n",
        "            trainer = CustomTFTrainer(\n",
        "                          model = trained_model,\n",
        "                          args = training_args,\n",
        "                      )\n",
        "\n",
        "            trainer.predict(test_dataset, num_test_examples, query_doc_ids, test_qrels, \n",
        "                            f'{data_args.test_set_name}_{data_args.out_suffix}-{global_step}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.24.90.66:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/training_args_tf.py:216: FutureWarning: The n_gpu argument is deprecated and will be removed in a future version, use n_replicas instead.\n",
            "  FutureWarning,\n",
            "WARNING:tensorflow:TPU system grpc://10.24.90.66:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.24.90.66:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.24.90.66:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "INFO:absl:n_gpu: 8, distributed training: True, 16-bits training: False\n",
            "INFO:absl:Training/evaluation/prediction parameters CustomTFTrainingArguments(output_dir='gs://lila_data/output_dir/zero-shot/robust04/electra', overwrite_output_dir=False, do_train=False, do_eval=False, do_predict=True, evaluate_during_training=False, evaluation_strategy='no', prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=3e-06, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=-1, max_steps=100000, warmup_steps=10000, logging_dir='gs://lila_data/log', logging_first_step=False, logging_steps=1000, save_steps=5000, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=16, dataloader_num_workers=0, past_index=-1, run_name=None, disable_tqdm=None, remove_unused_columns=True, label_names=None, tpu_name=None, xla=False, warmup_prop=0.0, patience=20, best_score=None, delta=0, do_early_stopping=False, ckpt_name='electra_ckpts', ckpt_dir='/content/drive/MyDrive/Colab Notebooks/electra_ckpts/sim_pair_wrap_2', tf_ckpt_dir='gs://lila_data/output_dir/zero-shot/robust04/electra/tf_ckpt_electra_ckpts', overwrite_ckpt_dir=False, overwrite_tf_ckpt_dir=False, max_ckpt_keep=3, save_all_ckpts=False, eval_all_checkpoints=False)\n",
            "INFO:absl:Evaluate the following checkpoints: ['/content/drive/MyDrive/Colab Notebooks/electra_ckpts/sim_pair_wrap_2']\n",
            "INFO:absl:Evaluate the following checkpoint-step: /content/drive/MyDrive/Colab Notebooks/electra_ckpts/sim_pair_wrap_2 - final\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluate the following checkpoint-step: /content/drive/MyDrive/Colab Notebooks/electra_ckpts/sim_pair_wrap_2 final\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFElectraForRelevanceClassification.\n",
            "\n",
            "All the weights of TFElectraForRelevanceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/electra_ckpts/sim_pair_wrap_2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForRelevanceClassification for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'Modeling.reRankers.TFElectraForRelevanceClassification'>\n",
            "<Modeling.reRankers.TFElectraRelevanceHead object at 0x7fed67ac4e10>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:***** Running Prediction *****\n",
            "INFO:absl:  Num examples = 2213519\n",
            "INFO:absl:  Batch size = 32\n",
            "Iteration: 100%|██████████| 69173/69173 [2:33:47<00:00,  7.50it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MajStVy8FpU-"
      },
      "source": [
        "# Multi_phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyY2kSurOblb"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch0zgi0SF5l2",
        "outputId": "159fece7-c278-4874-c978-d4e80a167fb9"
      },
      "source": [
        "## Tain params\n",
        "MODEL_NAME_OR_PATH = \"/path/to/msmarco-ft/ckpt\" #@param {type:\"string\"}\n",
        "#MODEL_TYPE='bert' #@param {type:\"string\"}\n",
        "\n",
        "RUNID=\"test-e1-lr1e5-b32_32\"#@param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/path/output/dir/for/predictions\" #@param {type:\"string\"}\n",
        "assert OUTPUT_DIR, 'Must specify an existing GCS bucket name'\n",
        "tf.io.gfile.makedirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# Now we need to specify the input data dir. Should contain the .tfrecord files \n",
        "# and the supporting query-docids mapping files.\n",
        "\n",
        "COLLECTION='gov2' #@param {type:\"string\"}\n",
        "\n",
        "STRATEGY= \"sim_pair\" #@param {type:\"string\"}\n",
        "\n",
        "FOLD_DATA_DIR = \"gs://BUCKET_NAME/gov2/gov2_description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs\" #@param {type:\"string\"}\n",
        "\n",
        "EVAL_QRELS_FILE='gs://path/to/qrels.txt/file' #@param {type:\"string\"}\n",
        "\n",
        "CKPT_DIR = \"/path/to/save/transformers/ckpts\"#@param {type:\"string\"}\n",
        "\n",
        "OUT_SUFFIX = \"msmarco-indomain\"#@param {type:\"string\"}\n",
        "\n",
        "TREC_METRICS= \"P_20 map ndcg_cut_20\"#@param {type:\"string\"}\n",
        "\n",
        "LOG_DIR = \"gs://BUCKET_NAME/log_dir\"#@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbWX5fEzPVdT"
      },
      "source": [
        "## Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjbr9jYVvQ98",
        "outputId": "b04ad30c-f397-4d66-8877-829ec24b9a88"
      },
      "source": [
        "# coding=utf-8\n",
        "from absl import logging as logger\n",
        "import os, glob, re\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import (\n",
        "    TF2_WEIGHTS_NAME,\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    HfArgumentParser,\n",
        "    PreTrainedTokenizer,\n",
        "    TFAutoModelForSequenceClassification,\n",
        "    TFTrainingArguments,\n",
        ")\n",
        "\n",
        "from Modeling import (\n",
        "    CustomTFTrainer,\n",
        "    CustomTFTrainingArguments,\n",
        "    get_eval_metric,\n",
        "    TFElectraForRelevanceClassification,\n",
        "    wrap_relevance_head,\n",
        ")\n",
        "from args import (\n",
        "    ModelArguments,\n",
        "    DataTrainingArguments,\n",
        ")\n",
        "\n",
        "\n",
        "logger.set_verbosity(logger.INFO)\n",
        "\n",
        "\n",
        "def get_trec_metrics():\n",
        "  return set(TREC_METRICS.split())\n",
        "\n",
        "def main(training_args, data_args, model_args):\n",
        "\n",
        "    logger.info(\n",
        "        \"n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        training_args.n_gpu,\n",
        "        bool(training_args.n_gpu > 1),\n",
        "        training_args.fp16,\n",
        "    )\n",
        "    logger.info(\"Training/evaluation/prediction parameters %s\", training_args)\n",
        "\n",
        "    if training_args.do_train or training_args.do_eval:\n",
        "       \n",
        "        num_labels = 2\n",
        "        output_mode = 'classification'\n",
        "\n",
        "        # Load pretrained model and tokenizer\n",
        "        #\n",
        "        # Distributed training:\n",
        "        # The .from_pretrained methods guarantee that only one local process can concurrently\n",
        "        # download model & vocab.\n",
        "\n",
        "        config = AutoConfig.from_pretrained(\n",
        "            model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
        "            num_labels=num_labels,\n",
        "            cache_dir=model_args.cache_dir,\n",
        "            output_hidden_states=False,\n",
        "        )\n",
        "\n",
        "        with training_args.strategy.scope():\n",
        "            # if MODEL_TYPE.lower()=='electra':\n",
        "            #   model = TFElectraForRelevanceClassification.from_pretrained(\n",
        "            #       model_args.model_name_or_path,\n",
        "            #       from_pt=True if glob.glob(f\"{model_args.model_name_or_path}/*.bin\") else False,\n",
        "            #       config=config,\n",
        "            #       cache_dir=model_args.cache_dir,\n",
        "            #   )\n",
        "            # else:\n",
        "            #   model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "            #       model_args.model_name_or_path,\n",
        "            #       from_pt=True if glob.glob(f\"{model_args.model_name_or_path}/*.bin\") else False,\n",
        "            #       config=config,\n",
        "            #       cache_dir=model_args.cache_dir,\n",
        "            #   )\n",
        "            model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "                  model_args.model_name_or_path,\n",
        "                  from_pt=True if glob.glob(f\"{model_args.model_name_or_path}/*.bin\") else False,\n",
        "                  config=config,\n",
        "                  cache_dir=model_args.cache_dir,\n",
        "              )\n",
        "            model = wrap_relevance_head(model)\n",
        "\n",
        "        # Get datasets\n",
        "        if training_args.do_train:\n",
        "            filename = os.path.join(data_args.train_data_dir, f'dataset_train_{data_args.train_set_name}.tf')\n",
        "\n",
        "            print('============== Train= ', filename)\n",
        "            if tf.io.gfile.exists(filename):\n",
        "                train_dataset, num_train_examples = data_args.doc_processor.get_train_dataset(filename, \n",
        "                                                                            training_args.train_batch_size, training_args.seed)\n",
        "            else:\n",
        "                raise IOError('File does not exist: ', filename)\n",
        "        else:\n",
        "            train_dataset, num_train_examples = None, 0\n",
        "\n",
        "        if training_args.do_eval or training_args.do_early_stopping:\n",
        "            filename = os.path.join(data_args.eval_data_dir, f'dataset_test_{data_args.eval_set_name}.tf')\n",
        "            print('============== Eval= ', filename)\n",
        "            ids_file = os.path.join(data_args.eval_data_dir, f'query_pass_ids_test_{data_args.eval_set_name}.tsv')\n",
        "            if tf.io.gfile.exists(filename):\n",
        "                eval_dataset, num_eval_examples = data_args.doc_processor.get_eval_dataset(filename, \n",
        "                                                                        training_args.eval_batch_size)\n",
        "            else:\n",
        "                raise IOError('File does not exist: ', filename)\n",
        "            if tf.io.gfile.exists(ids_file):\n",
        "                query_doc_ids = pd.read_csv(ids_file, \n",
        "                                            header=None, index_col=None, delimiter='\\t', \n",
        "                                            names=['id','qid','did','pass'], \n",
        "                                            dtype={'id':str, 'qid':str,'did':str})\n",
        "            else:\n",
        "                raise IOError('File does not exist: ', ids_file)\n",
        "\n",
        "            if data_args.eval_qrels_file is not None:\n",
        "                #qrels_file = os.path.join(data_args.eval_data_dir, data_args.eval_qrels_file)\n",
        "                qrels_file = os.path.join(data_args.eval_qrels_file)\n",
        "                if tf.io.gfile.exists(qrels_file):\n",
        "                    eval_qrels = pd.read_csv(qrels_file,\n",
        "                                header=None, index_col=None, delimiter=' ', names=['qid','_','did','label'], \n",
        "                                dtype={'qid':str,'did':str, 'label':int})\n",
        "                else:\n",
        "                    raise IOError('File does not exist: ', qrels_file)\n",
        "            else:\n",
        "                eval_qrels = None\n",
        "        else:\n",
        "            eval_dataset, num_eval_examples, query_doc_ids, eval_qrels = None, 0, None, None\n",
        "\n",
        "        trec_metrics = get_trec_metrics()\n",
        "\n",
        "        # Initialize our Trainer\n",
        "        trainer = CustomTFTrainer(\n",
        "            model = model,\n",
        "            args = training_args,\n",
        "            train_dataset = train_dataset,\n",
        "            num_train_examples = num_train_examples,\n",
        "            eval_dataset = eval_dataset,\n",
        "            num_eval_examples = num_eval_examples,\n",
        "            out_suffix = f'{data_args.eval_set_name}_{data_args.out_suffix}', # eval output file name\n",
        "            trec_metrics = trec_metrics,\n",
        "            query_doc_ids = query_doc_ids,\n",
        "            eval_qrels = eval_qrels,\n",
        "        )\n",
        "\n",
        "        # Training\n",
        "        if training_args.do_train:\n",
        "            r = trainer.evaluate(step=0)\n",
        "\n",
        "            print('step 0')\n",
        "            print(r)\n",
        "            trainer.train()\n",
        "\n",
        "            if not training_args.do_early_stopping:\n",
        "                trainer.save_model()\n",
        "\n",
        "        # Evaluation        \n",
        "        if training_args.do_eval:\n",
        "            results = trainer.evaluate(step='final')\n",
        "            print('final')\n",
        "            print(results)\n",
        "            \n",
        "    # Test\n",
        "    if training_args.do_predict:\n",
        "\n",
        "        checkpoints = list(\n",
        "                os.path.dirname(c)\n",
        "                for c in sorted(\n",
        "                    glob.glob(f'{training_args.ckpt_dir}' + \"/**/\" + TF2_WEIGHTS_NAME, recursive=True),\n",
        "                    key=lambda f: int(\"\".join(filter(str.isdigit, f)) or -1),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        if len(checkpoints) == 0:\n",
        "            raise IOError('No checkpoint found at this location: ', training_args.ckpt_dir)\n",
        "\n",
        "        elif not training_args.eval_all_checkpoints:\n",
        "            if training_args.ckpt_dir in checkpoints:\n",
        "                checkpoints = [training_args.ckpt_dir]\n",
        "            else:\n",
        "                checkpoints = [checkpoints[-1]]    \n",
        "                    \n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "\n",
        "        filename = os.path.join(data_args.eval_data_dir, f'dataset_test_{data_args.test_set_name}.tf')\n",
        "        if tf.io.gfile.exists(filename):\n",
        "            test_dataset, num_test_examples = data_args.doc_processor.get_eval_dataset(filename, \n",
        "                                                    training_args.eval_batch_size)\n",
        "        else: \n",
        "            raise IOError('File does not exist: ', filename)\n",
        "\n",
        "        ids_file = os.path.join(data_args.eval_data_dir, f'query_pass_ids_test_{data_args.test_set_name}.tsv')\n",
        "        if tf.io.gfile.exists(ids_file):\n",
        "            query_doc_ids = pd.read_csv(ids_file,\n",
        "                                header=None, index_col=None, delimiter='\\t', \n",
        "                                names=['id','qid','did','pass'],\n",
        "                                dtype={'id':str, 'qid':str,'did':str})\n",
        "        else: \n",
        "            raise IOError('File does not exist: ', ids_file)\n",
        "\n",
        "        if data_args.test_qrels_file:\n",
        "            qrels_file = os.path.join(data_args.eval_data_dir, data_args.test_qrels_file)\n",
        "            if tf.io.gfile.exists(qrels_file):\n",
        "                test_qrels = pd.read_csv(qrels_file, \n",
        "                            header=None, index_col=None, delimiter=' ', \n",
        "                            names=['qid','_','did','label'], \n",
        "                            dtype={'qid':str,'did':str, 'label':int})\n",
        "                \n",
        "            else :\n",
        "                raise IOError('File does not exist: ', qrels_file)\n",
        "        else:\n",
        "            test_qrels = None\n",
        "\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if re.match(\".*checkpoint*-[0-9]\", checkpoint) else \"final\"\n",
        "            logger.info(\"Evaluate the following checkpoint-step: %s - %s\", checkpoint, global_step)\n",
        "            print(\"Evaluate the following checkpoint-step:\", checkpoint, global_step)\n",
        "\n",
        "            with training_args.strategy.scope():\n",
        "                # if MODEL_TYPE.lower()=='electra':\n",
        "                #   trained_model = TFElectraForRelevanceClassification.from_pretrained(checkpoint)\n",
        "                # else:\n",
        "                #   trained_model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "                trained_model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "                trained_model = wrap_relevance_head(trained_model)\n",
        "\n",
        "            trainer = CustomTFTrainer(\n",
        "                          model = trained_model,\n",
        "                          args = training_args,\n",
        "                      )\n",
        "\n",
        "            trainer.predict(test_dataset, num_test_examples, query_doc_ids, test_qrels, \n",
        "                            f'{data_args.test_set_name}_{data_args.out_suffix}-{global_step}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    for fold in [1,2,3,4,5]:\n",
        "        print(\"============== fold= \",fold)\n",
        "        print(\"============== Strategy= \", STRATEGY)\n",
        "\n",
        "        num_eval_docs=100\n",
        "\n",
        "        fold_path = f'{FOLD_DATA_DIR}/fold-{fold}-train-1000-test-{num_eval_docs}'\n",
        "\n",
        "        training_args = CustomTFTrainingArguments(\n",
        "            output_dir = f'{OUTPUT_DIR}/{RUNID}/fold-{fold}-train-1000-test-{num_eval_docs}',\n",
        "            do_train = True,\n",
        "            do_eval = True,\n",
        "            do_predict = False,\n",
        "            do_early_stopping = False,\n",
        "            evaluate_during_training = True,\n",
        "            per_device_train_batch_size = 4,\n",
        "            per_device_eval_batch_size = 4,\n",
        "            learning_rate= 1e-5,\n",
        "            weight_decay = 0.01,\n",
        "            adam_epsilon = 1e-6,\n",
        "            num_train_epochs = 1,\n",
        "            max_steps = 0,\n",
        "            warmup_steps = 0,\n",
        "            warmup_prop = 0.1,\n",
        "            logging_steps = 1000,\n",
        "            save_steps = 10000000,\n",
        "            tpu_name = f\"grpc://{os.environ['COLAB_TPU_ADDR']}\",\n",
        "            eval_steps = 25000000,\n",
        "            patience = 20,\n",
        "            best_score = None,\n",
        "            delta = 0,\n",
        "            ckpt_name = f'{STRATEGY}_fold-{fold}', # see CustomTFTrainingArguments for more details about the ckpts\n",
        "            ckpt_dir=f\"{CKPT_DIR}/{RUNID}/fold-{fold}/ckpt_{STRATEGY}_fold-{fold}\", # Where the Transformers library ckpts format will be saved \n",
        "            eval_all_checkpoints = False,\n",
        "            logging_dir = LOG_DIR,\n",
        "            overwrite_ckpt_dir=True, # Overwirtes the ckpts saved in ckpt_dir if already exsits\n",
        "            overwrite_tf_ckpt_dir=True, # Overwirtes the TF2 ckpts saved in tf_ckpt_dir if already exsits, i.e Do not continue training from last ckpt\n",
        "        )\n",
        "\n",
        "        data_args = DataTrainingArguments(\n",
        "          collection = COLLECTION,\n",
        "          how = 'words',\n",
        "          train_data_dir = f'{FOLD_DATA_DIR}/fold-{fold}-train-1000-test-100',\n",
        "          eval_data_dir = f'{FOLD_DATA_DIR}/fold-{fold}-train-1000-test-100',\n",
        "          train_set_name = f'{COLLECTION}-fold-{fold}-{STRATEGY}',\n",
        "          eval_set_name = f'{COLLECTION}-fold-{fold}-{STRATEGY}_doc_level_marking',\n",
        "          eval_qrels_file = EVAL_QRELS_FILE,\n",
        "          out_suffix = OUT_SUFFIX,\n",
        "          max_seq_length = 256,\n",
        "        )\n",
        "        \n",
        "        model_args = ModelArguments(\n",
        "            model_name_or_path = f'{MODEL_NAME_OR_PATH}/{STRATEGY}', # initialize with the msmarco fine-tuned ckpt \n",
        "        )\n",
        "\n",
        "        main(training_args, data_args, model_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============== fold=  1\n",
            "============== Strategy=  sim_pair\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.8.155.18:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/training_args_tf.py:216: FutureWarning: The n_gpu argument is deprecated and will be removed in a future version, use n_replicas instead.\n",
            "  FutureWarning,\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.8.155.18:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "INFO:absl:n_gpu: 8, distributed training: True, 16-bits training: False\n",
            "INFO:absl:Training/evaluation/prediction parameters CustomTFTrainingArguments(output_dir='gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-1-train-1000-test-100', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=True, evaluation_strategy='no', prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-06, max_grad_norm=1.0, num_train_epochs=1, max_steps=0, warmup_steps=0, logging_dir='gs://lila_data/log', logging_first_step=False, logging_steps=1000, save_steps=10000000, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=25000000, dataloader_num_workers=0, past_index=-1, run_name=None, disable_tqdm=None, remove_unused_columns=True, label_names=None, tpu_name=None, xla=False, warmup_prop=0.1, patience=20, best_score=None, delta=0, do_early_stopping=False, ckpt_name='sim_pair_fold-1', ckpt_dir='/content/drive/MyDrive/Colab Notebooks/gov2/electra/hybrid/num-seg-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-1/ckpt_sim_pair_fold-1', tf_ckpt_dir='gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-1-train-1000-test-100/tf_ckpt_sim_pair_fold-1', overwrite_ckpt_dir=True, overwrite_tf_ckpt_dir=True, max_ckpt_keep=3, save_all_ckpts=False, eval_all_checkpoints=False)\n",
            "All model checkpoint weights were used when initializing TFElectraForRelevanceClassification.\n",
            "\n",
            "All the weights of TFElectraForRelevanceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/electra_ckpts/sim_pair_wrap.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForRelevanceClassification for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "============== Train=  gs://lila_data/trec/parade_style/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/fold-1-train-1000-test-100/dataset_train_gov2-fold-1-sim_pair.tf\n",
            "============== Eval=  gs://lila_data/trec/parade_style/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/fold-1-train-1000-test-100/dataset_test_gov2-fold-1-sim_pair_doc_level_marking.tf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "INFO:absl:***** Running training *****\n",
            "INFO:absl:  Num examples = 326169\n",
            "INFO:absl:  Num Epochs = 1\n",
            "INFO:absl:  Total optimization steps = 10192\n",
            "INFO:absl:Starting Epoch 1 ...\n",
            "INFO:absl:Epoch 1 Step 1000 Train Loss 0.1361\n",
            "INFO:absl:Epoch 1 Step 2000 Train Loss 0.4282\n",
            "INFO:absl:Epoch 1 Step 3000 Train Loss 0.2414\n",
            "INFO:absl:Epoch 1 Step 4000 Train Loss 0.2848\n",
            "INFO:absl:Epoch 1 Step 5000 Train Loss 0.0422\n",
            "INFO:absl:Epoch 1 Step 6000 Train Loss 0.3037\n",
            "INFO:absl:Epoch 1 Step 7000 Train Loss 0.0826\n",
            "INFO:absl:Epoch 1 Step 8000 Train Loss 0.3898\n",
            "INFO:absl:Epoch 1 Step 9000 Train Loss 0.5217\n",
            "INFO:absl:Epoch 1 Step 10000 Train Loss 0.3751\n",
            "INFO:absl:***** Running Evaluation *****\n",
            "INFO:absl:  Num examples = 60493\n",
            "INFO:absl:  Batch size = 32\n",
            "Iteration: 100%|██████████| 1891/1891 [03:36<00:00,  8.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "final\n",
            "{'loss': 2.1690347}\n",
            "============== fold=  2\n",
            "============== Strategy=  sim_pair\n",
            "WARNING:tensorflow:TPU system grpc://10.8.155.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.8.155.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.8.155.18:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.8.155.18:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "INFO:absl:n_gpu: 8, distributed training: True, 16-bits training: False\n",
            "INFO:absl:Training/evaluation/prediction parameters CustomTFTrainingArguments(output_dir='gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-2-train-1000-test-100', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=True, evaluation_strategy='no', prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-06, max_grad_norm=1.0, num_train_epochs=1, max_steps=0, warmup_steps=0, logging_dir='gs://lila_data/log', logging_first_step=False, logging_steps=1000, save_steps=10000000, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=25000000, dataloader_num_workers=0, past_index=-1, run_name=None, disable_tqdm=None, remove_unused_columns=True, label_names=None, tpu_name=None, xla=False, warmup_prop=0.1, patience=20, best_score=None, delta=0, do_early_stopping=False, ckpt_name='sim_pair_fold-2', ckpt_dir='/content/drive/MyDrive/Colab Notebooks/gov2/electra/hybrid/num-seg-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-2/ckpt_sim_pair_fold-2', tf_ckpt_dir='gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-2-train-1000-test-100/tf_ckpt_sim_pair_fold-2', overwrite_ckpt_dir=True, overwrite_tf_ckpt_dir=True, max_ckpt_keep=3, save_all_ckpts=False, eval_all_checkpoints=False)\n",
            "All model checkpoint weights were used when initializing TFElectraForRelevanceClassification.\n",
            "\n",
            "All the weights of TFElectraForRelevanceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/electra_ckpts/sim_pair_wrap.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForRelevanceClassification for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "============== Train=  gs://lila_data/trec/parade_style/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/fold-2-train-1000-test-100/dataset_train_gov2-fold-2-sim_pair.tf\n",
            "============== Eval=  gs://lila_data/trec/parade_style/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/fold-2-train-1000-test-100/dataset_test_gov2-fold-2-sim_pair_doc_level_marking.tf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:***** Running training *****\n",
            "INFO:absl:  Num examples = 329267\n",
            "INFO:absl:  Num Epochs = 1\n",
            "INFO:absl:  Total optimization steps = 10289\n",
            "INFO:absl:Starting Epoch 1 ...\n",
            "INFO:absl:Epoch 1 Step 1000 Train Loss 0.1880\n",
            "INFO:absl:Epoch 1 Step 2000 Train Loss 0.3849\n",
            "INFO:absl:Epoch 1 Step 3000 Train Loss 0.2406\n",
            "INFO:absl:Epoch 1 Step 4000 Train Loss 0.5292\n",
            "INFO:absl:Epoch 1 Step 5000 Train Loss 0.2059\n",
            "INFO:absl:Epoch 1 Step 6000 Train Loss 0.0018\n",
            "INFO:absl:Epoch 1 Step 7000 Train Loss 0.2795\n",
            "INFO:absl:Epoch 1 Step 8000 Train Loss 0.2156\n",
            "INFO:absl:Epoch 1 Step 9000 Train Loss 0.0118\n",
            "INFO:absl:Epoch 1 Step 10000 Train Loss 0.0851\n",
            "INFO:absl:***** Running Evaluation *****\n",
            "INFO:absl:  Num examples = 54828\n",
            "INFO:absl:  Batch size = 32\n",
            "Iteration: 100%|██████████| 1714/1714 [03:21<00:00,  8.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "final\n",
            "{'loss': 0.022328967}\n",
            "============== fold=  3\n",
            "============== Strategy=  sim_pair\n",
            "WARNING:tensorflow:TPU system grpc://10.8.155.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.8.155.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.8.155.18:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.8.155.18:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "INFO:absl:n_gpu: 8, distributed training: True, 16-bits training: False\n",
            "INFO:absl:Training/evaluation/prediction parameters CustomTFTrainingArguments(output_dir='gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-3-train-1000-test-100', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=True, evaluation_strategy='no', prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-06, max_grad_norm=1.0, num_train_epochs=1, max_steps=0, warmup_steps=0, logging_dir='gs://lila_data/log', logging_first_step=False, logging_steps=1000, save_steps=10000000, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=25000000, dataloader_num_workers=0, past_index=-1, run_name=None, disable_tqdm=None, remove_unused_columns=True, label_names=None, tpu_name=None, xla=False, warmup_prop=0.1, patience=20, best_score=None, delta=0, do_early_stopping=False, ckpt_name='sim_pair_fold-3', ckpt_dir='/content/drive/MyDrive/Colab Notebooks/gov2/electra/hybrid/num-seg-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-3/ckpt_sim_pair_fold-3', tf_ckpt_dir='gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-3-train-1000-test-100/tf_ckpt_sim_pair_fold-3', overwrite_ckpt_dir=True, overwrite_tf_ckpt_dir=True, max_ckpt_keep=3, save_all_ckpts=False, eval_all_checkpoints=False)\n",
            "All model checkpoint weights were used when initializing TFElectraForRelevanceClassification.\n",
            "\n",
            "All the weights of TFElectraForRelevanceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/electra_ckpts/sim_pair_wrap.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForRelevanceClassification for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "============== Train=  gs://lila_data/trec/parade_style/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/fold-3-train-1000-test-100/dataset_train_gov2-fold-3-sim_pair.tf\n",
            "============== Eval=  gs://lila_data/trec/parade_style/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/fold-3-train-1000-test-100/dataset_test_gov2-fold-3-sim_pair_doc_level_marking.tf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:***** Running training *****\n",
            "INFO:absl:  Num examples = 331077\n",
            "INFO:absl:  Num Epochs = 1\n",
            "INFO:absl:  Total optimization steps = 10346\n",
            "INFO:absl:Starting Epoch 1 ...\n",
            "INFO:absl:Epoch 1 Step 1000 Train Loss 0.5674\n",
            "INFO:absl:Epoch 1 Step 2000 Train Loss 0.1471\n",
            "INFO:absl:Epoch 1 Step 3000 Train Loss 0.4650\n",
            "INFO:absl:Epoch 1 Step 4000 Train Loss 0.4544\n",
            "INFO:absl:Epoch 1 Step 5000 Train Loss 0.3377\n",
            "INFO:absl:Epoch 1 Step 6000 Train Loss 0.2467\n",
            "INFO:absl:Epoch 1 Step 7000 Train Loss 0.0817\n",
            "INFO:absl:Epoch 1 Step 8000 Train Loss 0.4126\n",
            "INFO:absl:Epoch 1 Step 9000 Train Loss 0.4199\n",
            "INFO:absl:Epoch 1 Step 10000 Train Loss 0.1946\n",
            "INFO:absl:***** Running Evaluation *****\n",
            "INFO:absl:  Num examples = 58537\n",
            "INFO:absl:  Batch size = 32\n",
            "Iteration: 100%|██████████| 1830/1830 [03:37<00:00,  8.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "final\n",
            "{'loss': 0.0011912213}\n",
            "============== fold=  4\n",
            "============== Strategy=  sim_pair\n",
            "WARNING:tensorflow:TPU system grpc://10.8.155.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.8.155.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.8.155.18:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.8.155.18:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "INFO:absl:n_gpu: 8, distributed training: True, 16-bits training: False\n",
            "INFO:absl:Training/evaluation/prediction parameters CustomTFTrainingArguments(output_dir='gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-4-train-1000-test-100', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=True, evaluation_strategy='no', prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-06, max_grad_norm=1.0, num_train_epochs=1, max_steps=0, warmup_steps=0, logging_dir='gs://lila_data/log', logging_first_step=False, logging_steps=1000, save_steps=10000000, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=25000000, dataloader_num_workers=0, past_index=-1, run_name=None, disable_tqdm=None, remove_unused_columns=True, label_names=None, tpu_name=None, xla=False, warmup_prop=0.1, patience=20, best_score=None, delta=0, do_early_stopping=False, ckpt_name='sim_pair_fold-4', ckpt_dir='/content/drive/MyDrive/Colab Notebooks/gov2/electra/hybrid/num-seg-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-4/ckpt_sim_pair_fold-4', tf_ckpt_dir='gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-4-train-1000-test-100/tf_ckpt_sim_pair_fold-4', overwrite_ckpt_dir=True, overwrite_tf_ckpt_dir=True, max_ckpt_keep=3, save_all_ckpts=False, eval_all_checkpoints=False)\n",
            "All model checkpoint weights were used when initializing TFElectraForRelevanceClassification.\n",
            "\n",
            "All the weights of TFElectraForRelevanceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/electra_ckpts/sim_pair_wrap.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForRelevanceClassification for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "============== Train=  gs://lila_data/trec/parade_style/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/fold-4-train-1000-test-100/dataset_train_gov2-fold-4-sim_pair.tf\n",
            "============== Eval=  gs://lila_data/trec/parade_style/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/fold-4-train-1000-test-100/dataset_test_gov2-fold-4-sim_pair_doc_level_marking.tf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:***** Running training *****\n",
            "INFO:absl:  Num examples = 328882\n",
            "INFO:absl:  Num Epochs = 1\n",
            "INFO:absl:  Total optimization steps = 10277\n",
            "INFO:absl:Starting Epoch 1 ...\n",
            "INFO:absl:Epoch 1 Step 1000 Train Loss 0.4866\n",
            "INFO:absl:Epoch 1 Step 2000 Train Loss 0.1569\n",
            "INFO:absl:Epoch 1 Step 3000 Train Loss 0.2136\n",
            "INFO:absl:Epoch 1 Step 4000 Train Loss 0.4483\n",
            "INFO:absl:Epoch 1 Step 5000 Train Loss 0.3027\n",
            "INFO:absl:Epoch 1 Step 6000 Train Loss 0.0547\n",
            "INFO:absl:Epoch 1 Step 7000 Train Loss 0.4927\n",
            "INFO:absl:Epoch 1 Step 8000 Train Loss 0.4423\n",
            "INFO:absl:Epoch 1 Step 9000 Train Loss 0.2491\n",
            "INFO:absl:Epoch 1 Step 10000 Train Loss 0.7453\n",
            "INFO:absl:***** Running Evaluation *****\n",
            "INFO:absl:  Num examples = 57158\n",
            "INFO:absl:  Batch size = 32\n",
            "Iteration: 100%|██████████| 1787/1787 [03:33<00:00,  8.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "final\n",
            "{'loss': 0.2814586}\n",
            "============== fold=  5\n",
            "============== Strategy=  sim_pair\n",
            "WARNING:tensorflow:TPU system grpc://10.8.155.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.8.155.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.8.155.18:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.8.155.18:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "INFO:absl:n_gpu: 8, distributed training: True, 16-bits training: False\n",
            "INFO:absl:Training/evaluation/prediction parameters CustomTFTrainingArguments(output_dir='gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-5-train-1000-test-100', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=True, evaluation_strategy='no', prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-06, max_grad_norm=1.0, num_train_epochs=1, max_steps=0, warmup_steps=0, logging_dir='gs://lila_data/log', logging_first_step=False, logging_steps=1000, save_steps=10000000, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=25000000, dataloader_num_workers=0, past_index=-1, run_name=None, disable_tqdm=None, remove_unused_columns=True, label_names=None, tpu_name=None, xla=False, warmup_prop=0.1, patience=20, best_score=None, delta=0, do_early_stopping=False, ckpt_name='sim_pair_fold-5', ckpt_dir='/content/drive/MyDrive/Colab Notebooks/gov2/electra/hybrid/num-seg-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-5/ckpt_sim_pair_fold-5', tf_ckpt_dir='gs://lila_data/output_dir/in_domain/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/test-e1-lr1e5-b32_32/fold-5-train-1000-test-100/tf_ckpt_sim_pair_fold-5', overwrite_ckpt_dir=True, overwrite_tf_ckpt_dir=True, max_ckpt_keep=3, save_all_ckpts=False, eval_all_checkpoints=False)\n",
            "All model checkpoint weights were used when initializing TFElectraForRelevanceClassification.\n",
            "\n",
            "All the weights of TFElectraForRelevanceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/electra_ckpts/sim_pair_wrap.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForRelevanceClassification for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "============== Train=  gs://lila_data/trec/parade_style/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/fold-5-train-1000-test-100/dataset_train_gov2-fold-5-sim_pair.tf\n",
            "============== Eval=  gs://lila_data/trec/parade_style/gov2/electra/gov2_title-description_doc_body_p150_o75_256/num-pass-perdoc-30/train_sample_0.1_rawdocs/fold-5-train-1000-test-100/dataset_test_gov2-fold-5-sim_pair_doc_level_marking.tf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:***** Running training *****\n",
            "INFO:absl:  Num examples = 327037\n",
            "INFO:absl:  Num Epochs = 1\n",
            "INFO:absl:  Total optimization steps = 10219\n",
            "INFO:absl:Starting Epoch 1 ...\n",
            "INFO:absl:Epoch 1 Step 1000 Train Loss 0.4047\n",
            "INFO:absl:Epoch 1 Step 2000 Train Loss 0.5353\n",
            "INFO:absl:Epoch 1 Step 3000 Train Loss 0.1734\n",
            "INFO:absl:Epoch 1 Step 4000 Train Loss 0.2169\n",
            "INFO:absl:Epoch 1 Step 5000 Train Loss 0.0243\n",
            "INFO:absl:Epoch 1 Step 6000 Train Loss 0.2782\n",
            "INFO:absl:Epoch 1 Step 7000 Train Loss 0.0461\n",
            "INFO:absl:Epoch 1 Step 8000 Train Loss 0.3397\n",
            "INFO:absl:Epoch 1 Step 9000 Train Loss 0.1316\n",
            "INFO:absl:Epoch 1 Step 10000 Train Loss 0.1264\n",
            "INFO:absl:***** Running Evaluation *****\n",
            "INFO:absl:  Num examples = 57954\n",
            "INFO:absl:  Batch size = 32\n",
            "Iteration: 100%|██████████| 1812/1812 [03:36<00:00,  8.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "final\n",
            "{'loss': 0.18367758}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}